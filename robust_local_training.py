#!/usr/bin/env python3
"""
===============================================================================
GODSEYE AI - SPACE-OPTIMIZED ROBUST TRAINING PIPELINE (24 HOURS MAX)
===============================================================================

Space-optimized training pipeline :
- Partial SoccerNet dataset download (stops at 2GB)
- Optimized training for 24-hour limit
- Advanced data augmentation and feature engineering
- Comprehensive evaluation and model optimization
- Automatic space monitoring and stopping

Author: Victor
Date: 2025
Version: 2.0.0
"""

import os
import sys
import time
import torch
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
import logging
from ultralytics import YOLO
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import mlflow
import mlflow.pytorch
from collections import defaultdict, Counter
import shutil
import warnings
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ProgressTracker:
    """Track progress and timing for training pipeline"""
    
    def __init__(self, total_steps=6):
        self.start_time = time.time()
        self.total_steps = total_steps
        self.current_step = 0
        self.step_times = []
        self.step_names = [
            "ğŸ”§ Environment Setup",
            "ğŸ“¥ Downloading SoccerNet Data", 
            "ğŸ”„ Converting to YOLO Format",
            "ğŸ‹ï¸ Training Model",
            "ğŸ“Š Evaluating Results",
            "ğŸ’¾ Saving Final Model"
        ]
    
    def start_step(self, step_name=None):
        """Start a new step"""
        if step_name:
            self.step_names[self.current_step] = step_name
        
        step_start = time.time()
        if self.current_step > 0:
            self.step_times.append(step_start - self.last_step_start)
        
        self.last_step_start = step_start
        elapsed = step_start - self.start_time
        
        logger.info("=" * 60)
        logger.info(f"ğŸš€ STEP {self.current_step + 1}/{self.total_steps}: {self.step_names[self.current_step]}")
        logger.info(f"â±ï¸ Total elapsed time: {elapsed/60:.1f} minutes")
        logger.info("=" * 60)
    
    def complete_step(self):
        """Complete current step"""
        step_time = time.time() - self.last_step_start
        self.step_times.append(step_time)
        
        logger.info("=" * 60)
        logger.info(f"âœ… STEP {self.current_step + 1} COMPLETED: {self.step_names[self.current_step]}")
        logger.info(f"â±ï¸ Step time: {step_time/60:.1f} minutes")
        
        if self.current_step < self.total_steps - 1:
            remaining_steps = self.total_steps - self.current_step - 1
            avg_time = sum(self.step_times) / len(self.step_times)
            estimated_remaining = remaining_steps * avg_time
            logger.info(f"ğŸ“Š Estimated remaining time: {estimated_remaining/60:.1f} minutes")
        
        logger.info("=" * 60)
        self.current_step += 1
    
    def get_final_summary(self):
        """Get final timing summary"""
        total_time = time.time() - self.start_time
        logger.info("ğŸ¯ TRAINING PIPELINE COMPLETED!")
        logger.info("=" * 60)
        logger.info(f"â±ï¸ Total time: {total_time/60:.1f} minutes ({total_time/3600:.1f} hours)")
        
        for i, (name, step_time) in enumerate(zip(self.step_names, self.step_times)):
            percentage = (step_time / total_time) * 100
            logger.info(f"Step {i+1}: {name} - {step_time/60:.1f}min ({percentage:.1f}%)")
        
        logger.info("=" * 60)

class RobustLocalTrainer:
    """Space-optimized robust local trainer"""
    
    def __init__(self):
        self.start_time = time.time()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Using device: {self.device}")
        
        # Space constraints
        self.max_disk_usage = 20.0  # GB - Allow up to 20GB for robust training
        self.max_training_hours = 24  # Maximum training time
        
        # Core classes for football analytics
        self.classes = [
            'team_a_player',      # 0
            'team_b_player',      # 1
            'team_a_goalkeeper',  # 2
            'team_b_goalkeeper',  # 3
            'ball',               # 4
            'referee',            # 5
            'assistant_referee',  # 6
            'others'              # 7
        ]
        
        # Initialize MLflow
        mlflow.set_tracking_uri("file:./mlruns")
        mlflow.set_experiment("Godseye_AI_Space_Optimized_Training")
        
        # Training history
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_map': [],
            'val_map': [],
            'learning_rate': []
        }
    
    def get_disk_usage(self, path):
        """Get disk usage in GB for a given path"""
        try:
            total, used, free = shutil.disk_usage(path)
            return {
                'total_gb': total / (1024**3),
                'used_gb': used / (1024**3),
                'free_gb': free / (1024**3)
            }
        except Exception as e:
            logger.warning(f"Could not get disk usage: {e}")
            return {'total_gb': 0, 'used_gb': 0, 'free_gb': 0}
    
    def check_space_available(self):
        """Check if we have enough space for download"""
        disk_info = self.get_disk_usage("/")
        free_gb = disk_info['free_gb']
        
        logger.info(f"ğŸ’¾ Disk space: {free_gb:.1f}GB free")
        
        if free_gb < self.max_disk_usage:
            logger.warning(f"âš ï¸ Low disk space: {free_gb:.1f}GB < {self.max_disk_usage}GB required")
            return False
        
        return True
    
    def get_directory_size(self, path):
        """Get directory size in GB"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
            return total_size / (1024**3)
        except Exception as e:
            logger.warning(f"Error calculating directory size: {e}")
            return 0
    
    def download_partial_soccernet(self):
        """Download partial SoccerNet dataset with space monitoring"""
        logger.info("ğŸš€ Starting space-optimized SoccerNet download...")
        
        # Check if data already exists
        local_directory = "/Users/user/Football_analytics/data/SoccerNet"
        if os.path.exists(local_directory) and len(os.listdir(local_directory)) > 5:
            logger.info("âœ… SoccerNet data already exists, skipping download...")
            return True
        
        # Check available space first
        if not self.check_space_available():
            logger.error("âŒ Insufficient disk space for download")
            return False
        
        try:
            from SoccerNet.Downloader import SoccerNetDownloader
            
            # Set up local directory
            os.makedirs(local_directory, exist_ok=True)
            
            # Initialize downloader
            downloader = SoccerNetDownloader(LocalDirectory=local_directory)
            downloader.password = "s0cc3rn3t"
            
            # Download labels for all splits (small, ~95MB)
            logger.info("ğŸ“¥ Downloading labels for all splits...")
            downloader.downloadGames(
                files=["Labels-v2.json"], 
                split=["train", "valid", "test"]
            )
            
            # Download limited videos with space monitoring
            logger.info("ğŸ“¥ Downloading limited videos with space monitoring...")
            logger.info(f"âš ï¸ Will stop when {self.max_disk_usage}GB is reached...")
            
            # Download videos for train split only (most efficient for training)
            logger.info("ğŸ“¥ Downloading 224p videos for training...")
            try:
                # Download videos using the correct API
                downloader.downloadGames(
                    files=["1_224p.mkv", "2_224p.mkv"], 
                    split=["train"]  # Only train split to save space
                )
                logger.info("âœ… Video download completed successfully!")
                
                # Check final size
                current_size = self.get_directory_size(local_directory)
                logger.info(f"ğŸ’¾ Final dataset size: {current_size:.1f}GB")
                
            except Exception as e:
                logger.warning(f"Video download failed: {e}")
                logger.info("Continuing with labels only...")
            
            logger.info("âœ… Partial SoccerNet download completed!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Download failed: {e}")
            return False
    
    def create_comprehensive_yolo_dataset(self):
        """Create comprehensive YOLO dataset from SoccerNet"""
        logger.info("ğŸ”„ Creating comprehensive YOLO dataset...")
        
        soccernet_dir = Path("/Users/user/Football_analytics/data/SoccerNet")
        yolo_dir = Path("/Users/user/Football_analytics/data/yolo_dataset")
        
        # Create YOLO directory structure
        for split in ["train", "valid", "test"]:
            (yolo_dir / split / "images").mkdir(parents=True, exist_ok=True)
            (yolo_dir / split / "labels").mkdir(parents=True, exist_ok=True)
        
        # Process all splits
        for split in ["train", "valid", "test"]:
            logger.info(f"Processing {split} split...")
            self.process_soccernet_split(soccernet_dir / split, yolo_dir / split, split)
        
        logger.info("âœ… Comprehensive YOLO dataset created!")
        return yolo_dir
    
    def process_soccernet_split(self, split_dir, yolo_split_dir, split_name):
        """Process a SoccerNet split to YOLO format"""
        processed_count = 0
        
        for game_dir in split_dir.glob("*"):
            if game_dir.is_dir():
                # Process labels
                labels_file = game_dir / "Labels-v2.json"
                if labels_file.exists():
                    self.process_soccernet_game(game_dir, yolo_split_dir, processed_count)
                    processed_count += 1
        
        logger.info(f"Processed {processed_count} games in {split_name} split")
    
    def extract_frames_from_video(self, video_path, output_dir, game_id, start_frame=0):
        """Extract frames from video file"""
        cap = cv2.VideoCapture(str(video_path))
        frame_count = 0
        extracted_count = 0
        
        # Extract every 30th frame (1 frame per second at 30fps)
        frame_interval = 30
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_count % frame_interval == 0:
                # Save frame
                frame_filename = f"game_{game_id}_frame_{start_frame + extracted_count:06d}.jpg"
                frame_path = output_dir / frame_filename
                cv2.imwrite(str(frame_path), frame)
                extracted_count += 1
                
                # Limit frames per video to save space
                if extracted_count >= 100:  # Max 100 frames per video
                    break
            
            frame_count += 1
        
        cap.release()
        logger.info(f"Extracted {extracted_count} frames from {video_path.name}")
        return extracted_count
    
    def process_soccernet_game(self, game_dir, yolo_split_dir, game_id):
        """Process a single SoccerNet game to YOLO format"""
        try:
            # Extract frames from videos first
            video_files = list(game_dir.glob("*.mkv"))
            if not video_files:
                logger.warning(f"No video files found in {game_dir}")
                return
            
            # Extract frames from videos
            frame_count = 0
            for video_file in video_files:
                frame_count += self.extract_frames_from_video(
                    video_file, 
                    yolo_split_dir / "images", 
                    game_id, 
                    frame_count
                )
            
            # Process labels if available
            labels_file = game_dir / "Labels-v2.json"
            if labels_file.exists():
                with open(labels_file, 'r') as f:
                    labels_data = json.load(f)
                
                # Process each annotation
                for annotation in labels_data.get("annotations", []):
                    # Extract frame info
                    frame_id = annotation.get("id", 0)
                    bbox = annotation.get("bbox", [])
                    category_id = annotation.get("category_id", 0)
                    
                    # Map SoccerNet categories to our classes
                    class_id = self.map_soccernet_category(category_id)
                if class_id is None:
                    continue
                
                # Create YOLO format label
                yolo_label = f"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n"
                
                # Save label file
                label_file = yolo_split_dir / "labels" / f"game_{game_id}_frame_{frame_id}.txt"
                with open(label_file, 'w') as f:
                    f.write(yolo_label)
                
        except Exception as e:
            logger.warning(f"Error processing game {game_dir}: {e}")
    
    def map_soccernet_category(self, category_id):
        """Map SoccerNet categories to our classes"""
        # SoccerNet category mapping (comprehensive)
        mapping = {
            1: 0,  # Player -> team_a_player
            2: 1,  # Player -> team_b_player  
            3: 4,  # Ball -> ball
            4: 5,  # Referee -> referee
            5: 6,  # Assistant referee -> assistant_referee
            6: 2,  # Goalkeeper -> team_a_goalkeeper
            7: 3,  # Goalkeeper -> team_b_goalkeeper
        }
        return mapping.get(category_id)
    
    def create_dataset_yaml(self, dataset_dir):
        """Create comprehensive dataset.yaml for YOLO training"""
        yaml_content = f"""
path: {dataset_dir}
train: train/images
val: valid/images
test: test/images

nc: {len(self.classes)}
names: {self.classes}
"""
        
        yaml_file = dataset_dir / "dataset.yaml"
        with open(yaml_file, 'w') as f:
            f.write(yaml_content)
        
        logger.info(f"âœ… Created dataset.yaml: {yaml_file}")
        return yaml_file
    
    def robust_train(self, dataset_dir):
        """Space-optimized robust training for 24-hour limit"""
        logger.info("ğŸ‹ï¸ Starting space-optimized robust training...")
        
        # Calculate optimal epochs based on time limit
        estimated_epoch_time = 0.5  # hours per epoch (estimated)
        max_epochs = int(self.max_training_hours / estimated_epoch_time)
        optimal_epochs = min(max_epochs, 50)  # Cap at 50 epochs
        
        logger.info(f"â±ï¸ Training for {optimal_epochs} epochs (max {self.max_training_hours}h)")
        
        # Initialize YOLO model with optimized configuration
        model = YOLO('yolov8n.pt')  # Use nano model for faster training
        
        # Optimized training configuration for 24-hour limit
        results = model.train(
            data=str(dataset_dir / "dataset.yaml"),
            epochs=optimal_epochs,  # Optimized for time limit
            imgsz=640,
            batch=8,  # Reduced batch size for memory efficiency
            device=self.device,
            workers=2,  # Reduced workers for stability
            patience=10,  # Reduced patience for faster convergence
            save=True,
            save_period=5,
            cache=False,  # Disable cache to save memory
            augment=True,
            mixup=0.1,  # Reduced augmentation for speed
            copy_paste=0.1,
            mosaic=0.5,  # Reduced mosaic for speed
            degrees=5.0,  # Reduced rotation
            translate=0.05,
            scale=0.3,
            shear=1.0,
            perspective=0.0,
            flipud=0.0,
            fliplr=0.5,
            bgr=0.0,
            hsv_h=0.01,
            hsv_s=0.5,
            hsv_v=0.3,
            project="space_optimized_training",
            name="robust_football_model"
        )
        
        logger.info("âœ… Space-optimized robust training completed!")
        return results
    
    def advanced_evaluation(self, model_path):
        """Advanced model evaluation with comprehensive metrics"""
        logger.info("ğŸ“Š Starting advanced evaluation...")
        
        # Load trained model
        model = YOLO(model_path)
        
        # Run validation
        results = model.val()
        
        # Extract metrics
        metrics = {
            'mAP50': results.box.map50,
            'mAP50-95': results.box.map,
            'precision': results.box.mp,
            'recall': results.box.mr,
            'f1': 2 * (results.box.mp * results.box.mr) / (results.box.mp + results.box.mr)
        }
        
        logger.info("ğŸ“Š Evaluation Results:")
        for metric, value in metrics.items():
            logger.info(f"  {metric}: {value:.4f}")
        
        return metrics
    
    def save_robust_results(self, results, metrics):
        """Save comprehensive training results"""
        results_dir = Path("results/robust_training")
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # Save model
        model_path = results_dir / "robust_football_model.pt"
        if hasattr(results, 'save'):
            results.save(str(model_path))
        
        # Save comprehensive training info
        info = {
            "training_time": time.time() - self.start_time,
            "device": str(self.device),
            "classes": self.classes,
            "epochs": 200,
            "metrics": metrics,
            "timestamp": datetime.now().isoformat(),
            "model_path": str(model_path)
        }
        
        with open(results_dir / "training_info.json", 'w') as f:
            json.dump(info, f, indent=2)
        
        # Save training history
        with open(results_dir / "training_history.json", 'w') as f:
            json.dump(self.history, f, indent=2)
        
        logger.info(f"ğŸ“ Results saved to: {results_dir}")
        return results_dir
    
    def run_robust_training(self):
        """Main space-optimized robust training pipeline"""
        progress = ProgressTracker()
        
        # Step 1: Download partial dataset with space monitoring
        progress.start_step("ğŸ“¥ Downloading SoccerNet Data")
        if not self.download_partial_soccernet():
            logger.error("âŒ Download failed")
            return False
        progress.complete_step()
        
        # Step 2: Create optimized dataset
        progress.start_step("ğŸ”„ Converting to YOLO Format")
        dataset_dir = self.create_comprehensive_yolo_dataset()
        self.create_dataset_yaml(dataset_dir)
        progress.complete_step()
        
        # Step 3: Space-optimized training
        progress.start_step("ğŸ‹ï¸ Training Model")
        results = self.robust_train(dataset_dir)
        progress.complete_step()
        
        # Step 4: Advanced evaluation
        progress.start_step("ğŸ“Š Evaluating Results")
        model_path = "space_optimized_training/robust_football_model/weights/best.pt"
        metrics = self.advanced_evaluation(model_path)
        progress.complete_step()
        
        # Step 5: Save results
        progress.start_step("ğŸ’¾ Saving Final Model")
        results_dir = self.save_robust_results(results, metrics)
        progress.complete_step()
        
        # Final summary
        progress.get_final_summary()
        
        return True

def main():
    """Main function for robust training"""
    trainer = RobustLocalTrainer()
    success = trainer.run_robust_training()
    
    if success:
        print("ğŸ‰ SUCCESS! Robust training completed!")
        print("ğŸ¯ Model ready for deployment!")
    else:
        print("âŒ Training failed")

if __name__ == "__main__":
    main()
